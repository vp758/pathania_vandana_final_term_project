{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d641e0c-5bcd-4416-8726-f5dcead6c28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   type_school            1000 non-null   object \n",
      " 1   school_accreditation   1000 non-null   object \n",
      " 2   gender                 1000 non-null   object \n",
      " 3   interest               1000 non-null   object \n",
      " 4   residence              1000 non-null   object \n",
      " 5   parent_age             1000 non-null   int64  \n",
      " 6   parent_salary          1000 non-null   int64  \n",
      " 7   house_area             1000 non-null   float64\n",
      " 8   average_grades         1000 non-null   float64\n",
      " 9   parent_was_in_college  1000 non-null   bool   \n",
      " 10  will_go_to_college     1000 non-null   bool   \n",
      "dtypes: bool(2), float64(2), int64(2), object(5)\n",
      "memory usage: 72.4+ KB\n",
      "None\n",
      "   type_school  school_accreditation    gender  interest  residence  \\\n",
      "0    -0.801272             -1.038750  0.970437 -1.058331   0.924818   \n",
      "1    -0.801272             -1.038750  0.970437 -1.058331   0.924818   \n",
      "2    -0.801272              0.962695 -1.030464  1.086935   0.924818   \n",
      "3     1.248016              0.962695  0.970437  1.086935  -1.081294   \n",
      "4    -0.801272             -1.038750 -1.030464  1.086935   0.924818   \n",
      "\n",
      "   parent_age  parent_salary  house_area  average_grades  \\\n",
      "0    1.083838       1.122836    0.555074       -0.594365   \n",
      "1    1.369661      -0.695545    0.149467        0.240684   \n",
      "2   -0.631096       0.800682    0.398065        0.394664   \n",
      "3   -0.916918       0.872272    0.241055       -1.177715   \n",
      "4    1.369661      -0.094191    0.038251        0.205150   \n",
      "\n",
      "   parent_was_in_college  \n",
      "0              -1.040833  \n",
      "1              -1.040833  \n",
      "2              -1.040833  \n",
      "3               0.960769  \n",
      "4              -1.040833  \n",
      "\n",
      "Metrics for Algorithm KNN:\n",
      "\n",
      "             iter1  iter2  iter3  iter4  iter5  iter6  iter7  iter8  iter9  \\\n",
      "TP           40.00  37.00  37.00  34.00  42.00  41.00  41.00  37.00  40.00   \n",
      "TN           41.00  37.00  43.00  39.00  34.00  37.00  40.00  38.00  43.00   \n",
      "FP            4.00   8.00   2.00   6.00  11.00   8.00   5.00   7.00   2.00   \n",
      "FN            5.00   8.00   8.00  11.00   3.00   4.00   4.00   8.00   5.00   \n",
      "TPR           0.89   0.82   0.82   0.76   0.93   0.91   0.91   0.82   0.89   \n",
      "TNR           0.91   0.82   0.96   0.87   0.76   0.82   0.89   0.84   0.96   \n",
      "FPR           0.09   0.18   0.04   0.13   0.24   0.18   0.11   0.16   0.04   \n",
      "FNR           0.11   0.18   0.18   0.24   0.07   0.09   0.09   0.18   0.11   \n",
      "Precision     0.91   0.82   0.95   0.85   0.79   0.84   0.89   0.84   0.95   \n",
      "F1_measure    0.90   0.82   0.88   0.80   0.86   0.87   0.90   0.83   0.92   \n",
      "Accuracy      0.90   0.82   0.89   0.81   0.84   0.87   0.90   0.83   0.92   \n",
      "Error_rate    0.10   0.18   0.11   0.19   0.16   0.13   0.10   0.17   0.08   \n",
      "BACC          0.90   0.82   0.89   0.81   0.84   0.87   0.90   0.83   0.92   \n",
      "TSS           0.80   0.64   0.78   0.62   0.69   0.73   0.80   0.67   0.84   \n",
      "HSS           0.80   0.64   0.78   0.62   0.69   0.73   0.80   0.67   0.84   \n",
      "Brier_score   0.08   0.12   0.09   0.12   0.11   0.10   0.08   0.11   0.08   \n",
      "AUC           0.96   0.92   0.96   0.91   0.93   0.94   0.96   0.92   0.96   \n",
      "\n",
      "             iter10  \n",
      "TP            40.00  \n",
      "TN            43.00  \n",
      "FP             2.00  \n",
      "FN             5.00  \n",
      "TPR            0.89  \n",
      "TNR            0.96  \n",
      "FPR            0.04  \n",
      "FNR            0.11  \n",
      "Precision      0.95  \n",
      "F1_measure     0.92  \n",
      "Accuracy       0.92  \n",
      "Error_rate     0.08  \n",
      "BACC           0.92  \n",
      "TSS            0.84  \n",
      "HSS            0.84  \n",
      "Brier_score    0.07  \n",
      "AUC            0.97  \n",
      "\n",
      "\n",
      "\n",
      "Metrics for Algorithm RF:\n",
      "\n",
      "             iter1  iter2  iter3  iter4  iter5  iter6  iter7  iter8  iter9  \\\n",
      "TP           41.00  40.00  39.00  39.00  43.00  44.00  40.00  40.00  40.00   \n",
      "TN           33.00  38.00  42.00  44.00  34.00  40.00  42.00  40.00  42.00   \n",
      "FP           12.00   7.00   3.00   1.00  11.00   5.00   3.00   5.00   3.00   \n",
      "FN            4.00   5.00   6.00   6.00   2.00   1.00   5.00   5.00   5.00   \n",
      "TPR           0.91   0.89   0.87   0.87   0.96   0.98   0.89   0.89   0.89   \n",
      "TNR           0.73   0.84   0.93   0.98   0.76   0.89   0.93   0.89   0.93   \n",
      "FPR           0.27   0.16   0.07   0.02   0.24   0.11   0.07   0.11   0.07   \n",
      "FNR           0.09   0.11   0.13   0.13   0.04   0.02   0.11   0.11   0.11   \n",
      "Precision     0.77   0.85   0.93   0.98   0.80   0.90   0.93   0.89   0.93   \n",
      "F1_measure    0.84   0.87   0.90   0.92   0.87   0.94   0.91   0.89   0.91   \n",
      "Accuracy      0.82   0.87   0.90   0.92   0.86   0.93   0.91   0.89   0.91   \n",
      "Error_rate    0.18   0.13   0.10   0.08   0.14   0.07   0.09   0.11   0.09   \n",
      "BACC          0.82   0.87   0.90   0.92   0.86   0.93   0.91   0.89   0.91   \n",
      "TSS           0.64   0.73   0.80   0.84   0.71   0.87   0.82   0.78   0.82   \n",
      "HSS           0.64   0.73   0.80   0.84   0.71   0.87   0.82   0.78   0.82   \n",
      "Brier_score   0.10   0.10   0.08   0.08   0.10   0.06   0.07   0.08   0.06   \n",
      "AUC           0.95   0.94   0.97   0.95   0.95   0.98   0.98   0.97   0.98   \n",
      "\n",
      "             iter10  \n",
      "TP            39.00  \n",
      "TN            43.00  \n",
      "FP             2.00  \n",
      "FN             6.00  \n",
      "TPR            0.87  \n",
      "TNR            0.96  \n",
      "FPR            0.04  \n",
      "FNR            0.13  \n",
      "Precision      0.95  \n",
      "F1_measure     0.91  \n",
      "Accuracy       0.91  \n",
      "Error_rate     0.09  \n",
      "BACC           0.91  \n",
      "TSS            0.82  \n",
      "HSS            0.82  \n",
      "Brier_score    0.07  \n",
      "AUC            0.98  \n",
      "\n",
      "\n",
      "\n",
      "Metrics for Algorithm LSTM:\n",
      "\n",
      "             iter1  iter2  iter3  iter4  iter5  iter6  iter7  iter8  iter9  \\\n",
      "TP           39.00  42.00  40.00  36.00  42.00  44.00  42.00  41.00  45.00   \n",
      "TN           33.00  36.00  39.00  43.00  40.00  44.00  45.00  41.00  44.00   \n",
      "FP           12.00   9.00   6.00   2.00   5.00   1.00   0.00   4.00   1.00   \n",
      "FN            6.00   3.00   5.00   9.00   3.00   1.00   3.00   4.00   0.00   \n",
      "TPR           0.87   0.93   0.89   0.80   0.93   0.98   0.93   0.91   1.00   \n",
      "TNR           0.73   0.80   0.87   0.96   0.89   0.98   1.00   0.91   0.98   \n",
      "FPR           0.27   0.20   0.13   0.04   0.11   0.02   0.00   0.09   0.02   \n",
      "FNR           0.13   0.07   0.11   0.20   0.07   0.02   0.07   0.09   0.00   \n",
      "Precision     0.76   0.82   0.87   0.95   0.89   0.98   1.00   0.91   0.98   \n",
      "F1_measure    0.81   0.88   0.88   0.87   0.91   0.98   0.97   0.91   0.99   \n",
      "Accuracy      0.80   0.87   0.88   0.88   0.91   0.98   0.97   0.91   0.99   \n",
      "Error_rate    0.20   0.13   0.12   0.12   0.09   0.02   0.03   0.09   0.01   \n",
      "BACC          0.80   0.87   0.88   0.88   0.91   0.98   0.97   0.91   0.99   \n",
      "TSS           0.60   0.73   0.76   0.76   0.82   0.96   0.93   0.82   0.98   \n",
      "HSS           0.60   0.73   0.76   0.76   0.82   0.96   0.93   0.82   0.98   \n",
      "Brier_score   0.14   0.09   0.09   0.10   0.06   0.02   0.03   0.07   0.00   \n",
      "AUC           0.90   0.95   0.96   0.95   0.98   1.00   1.00   0.98   1.00   \n",
      "\n",
      "             iter10  \n",
      "TP             45.0  \n",
      "TN             45.0  \n",
      "FP              0.0  \n",
      "FN              0.0  \n",
      "TPR             1.0  \n",
      "TNR             1.0  \n",
      "FPR             0.0  \n",
      "FNR             0.0  \n",
      "Precision       1.0  \n",
      "F1_measure      1.0  \n",
      "Accuracy        1.0  \n",
      "Error_rate      0.0  \n",
      "BACC            1.0  \n",
      "TSS             1.0  \n",
      "HSS             1.0  \n",
      "Brier_score     0.0  \n",
      "AUC             1.0  \n",
      "\n",
      "\n",
      "\n",
      "----- Average Performance for Each Algorithm -----\n",
      "\n",
      "               KNN     RF   LSTM\n",
      "TP           38.90  40.50  41.60\n",
      "TN           39.50  39.80  41.00\n",
      "FP            5.50   5.20   4.00\n",
      "FN            6.10   4.50   3.40\n",
      "TPR           0.86   0.90   0.92\n",
      "TNR           0.88   0.88   0.91\n",
      "FPR           0.12   0.12   0.09\n",
      "FNR           0.14   0.10   0.08\n",
      "Precision     0.88   0.89   0.92\n",
      "F1_measure    0.87   0.89   0.92\n",
      "Accuracy      0.87   0.89   0.92\n",
      "Error_rate    0.13   0.11   0.08\n",
      "BACC          0.87   0.89   0.92\n",
      "TSS           0.74   0.78   0.84\n",
      "HSS           0.74   0.78   0.84\n",
      "Brier_score   0.10   0.08   0.06\n",
      "AUC           0.94   0.96   0.97\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, brier_score_loss\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "def load_and_preprocess_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    print(\"Dataset Information:\")\n",
    "    print(data.info())\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    categorical_columns = ['type_school', 'school_accreditation', 'gender', 'interest', 'residence', 'parent_was_in_college', 'will_go_to_college']\n",
    "    label_encoders = {col: LabelEncoder().fit(data[col]) for col in categorical_columns}\n",
    "    for col, le in label_encoders.items():\n",
    "        data[col] = le.transform(data[col])\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = load_and_preprocess_data('pathania_vandana_final_term_project_data.csv')\n",
    "\n",
    "# Split the data into features and labels\n",
    "features = data.drop(['will_go_to_college'], axis=1)\n",
    "labels = data['will_go_to_college']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "feature_columns = data.drop(['will_go_to_college'], axis=1).columns\n",
    "features_df = pd.DataFrame(features, columns=feature_columns)\n",
    "print(features_df.head())\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=42, stratify=labels)\n",
    "\n",
    "# Define Stratified K-Fold cross-validator\n",
    "cv_stratified = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Define model parameters\n",
    "knn_params = {\"n_neighbors\": list(range(3, 20, 2))}\n",
    "rf_params = {\"n_estimators\": list(range(50, 201, 25)), \"min_samples_split\": [5, 10, 15, 20]}\n",
    "\n",
    "# Perform GridSearchCV for KNN and Random Forest\n",
    "def perform_grid_search(model, params, X_train, y_train):\n",
    "    cv = GridSearchCV(model, params, cv=10, n_jobs=-1)\n",
    "    cv.fit(X_train, y_train)\n",
    "    return cv.best_params_\n",
    "\n",
    "best_knn_params = perform_grid_search(KNeighborsClassifier(), knn_params, X_train, y_train)\n",
    "best_rf_params = perform_grid_search(RandomForestClassifier(), rf_params, X_train, y_train)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calc_metrics(y_true, y_pred, y_prob):\n",
    "    # Confusion matrix components\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    # Helper function to avoid division by zero\n",
    "    def safe_divide(numerator, denominator):\n",
    "        return numerator / denominator if denominator > 0 else 0\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'TP': TP,\n",
    "        'TN': TN,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'TPR': safe_divide(TP, TP + FN),  # True Positive Rate\n",
    "        'TNR': safe_divide(TN, TN + FP),  # True Negative Rate\n",
    "        'FPR': safe_divide(FP, TN + FP),  # False Positive Rate\n",
    "        'FNR': safe_divide(FN, TP + FN),  # False Negative Rate\n",
    "        'Precision': safe_divide(TP, TP + FP),  # Precision\n",
    "        'F1_measure': safe_divide(2 * TP, 2 * TP + FP + FN),  # F1 Measure\n",
    "        'Accuracy': safe_divide(TP + TN, TP + FP + FN + TN),  # Accuracy\n",
    "        'Error_rate': 1 - safe_divide(TP + TN, TP + FP + FN + TN),  # Error Rate\n",
    "        'BACC': safe_divide(safe_divide(TP, TP + FN) + safe_divide(TN, TN + FP), 2),  # Balanced Accuracy\n",
    "        'TSS': safe_divide(TP, TP + FN) - safe_divide(FP, TN + FP),  # True Skill Statistic\n",
    "        'HSS': safe_divide(2 * (TP * TN - FP * FN), ((TP + FN) * (FN + TN) + (TP + FP) * (FP + TN))),  # Heidke Skill Score\n",
    "        'Brier_score': brier_score_loss(y_true, y_prob),  # Brier Score\n",
    "        'AUC': roc_auc_score(y_true, y_prob)  # Area Under the Curve\n",
    "    }\n",
    "\n",
    "    # Return metrics as a list in a specific order\n",
    "    return [metrics[key] for key in ['TP', 'TN', 'FP', 'FN', 'TPR', 'TNR', 'FPR', 'FNR', 'Precision', 'F1_measure', 'Accuracy', 'Error_rate', 'BACC', 'TSS', 'HSS', 'Brier_score', 'AUC']]\n",
    "\n",
    "# Function to get metrics for models\n",
    "def get_metrics(model, X_train, X_test, y_train, y_test, lstm_flag=False):\n",
    "    if lstm_flag:\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "        model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "        y_prob = model.predict(X_test, verbose=0).flatten()\n",
    "        y_pred = (y_prob > 0.5).astype(int)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    return calc_metrics(y_test, y_pred, y_prob)\n",
    "\n",
    "# LSTM model definition\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, activation='relu', input_shape=(input_shape, 1), return_sequences=False))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "lstm_model = create_lstm_model(X_train.shape[1])\n",
    "\n",
    "# Initialize metric columns and lists\n",
    "metric_columns = ['TP', 'TN', 'FP', 'FN', 'TPR', 'TNR', 'FPR', 'FNR', 'Precision', 'F1_measure', 'Accuracy', 'Error_rate', 'BACC', 'TSS', 'HSS', 'Brier_score', 'AUC']\n",
    "knn_metrics_list, rf_metrics_list, lstm_metrics_list = [], [], []\n",
    "\n",
    "# 10 Iterations of 10-fold cross-validation\n",
    "for iter_num, (train_index, test_index) in enumerate(cv_stratified.split(X_train, y_train), start=1):\n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train.iloc[train_index].values, y_train.iloc[test_index].values\n",
    "    \n",
    "    # KNN Model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=best_knn_params['n_neighbors'])\n",
    "    # Random Forest Model\n",
    "    rf_model = RandomForestClassifier(min_samples_split=best_rf_params['min_samples_split'], n_estimators=best_rf_params['n_estimators'])\n",
    "    \n",
    "    # Get metrics for each algorithm\n",
    "    knn_metrics = get_metrics(knn_model, X_train_fold, X_test_fold, y_train_fold, y_test_fold, lstm_flag=False)\n",
    "    rf_metrics = get_metrics(rf_model, X_train_fold, X_test_fold, y_train_fold, y_test_fold, lstm_flag=False)\n",
    "    lstm_metrics = get_metrics(lstm_model, X_train_fold, X_test_fold, y_train_fold, y_test_fold, lstm_flag=True)\n",
    "    \n",
    "    # Append metrics to respective lists\n",
    "    knn_metrics_list.append(knn_metrics)\n",
    "    rf_metrics_list.append(rf_metrics)\n",
    "    lstm_metrics_list.append(lstm_metrics)\n",
    "    \n",
    "    # Create a DataFrame for all metrics in the current iteration\n",
    "    metrics_all_df = pd.DataFrame([knn_metrics, rf_metrics, lstm_metrics],\n",
    "                                  columns=metric_columns, index=['KNN', 'RF', 'LSTM'])\n",
    "\n",
    "# Create a DataFrame for the metrics of each algorithm\n",
    "metric_index_df = ['iter' + str(i) for i in range(1, 11)]\n",
    "knn_metrics_df = pd.DataFrame(knn_metrics_list, columns=metric_columns, index=metric_index_df)\n",
    "rf_metrics_df = pd.DataFrame(rf_metrics_list, columns=metric_columns, index=metric_index_df)\n",
    "lstm_metrics_df = pd.DataFrame(lstm_metrics_list, columns=metric_columns, index=metric_index_df)\n",
    "\n",
    "# Display metrics for each algorithm in each iteration\n",
    "for algo_name, metrics_df in zip(['KNN', 'RF', 'LSTM'], [knn_metrics_df, rf_metrics_df, lstm_metrics_df]):\n",
    "    print('\\nMetrics for Algorithm {}:\\n'.format(algo_name))\n",
    "    print(metrics_df.round(decimals=2).T)\n",
    "    print('\\n')\n",
    "\n",
    "# Calculate the average metrics for each algorithm\n",
    "knn_avg_df = knn_metrics_df.mean()\n",
    "rf_avg_df = rf_metrics_df.mean()\n",
    "lstm_avg_df = lstm_metrics_df.mean()\n",
    "\n",
    "# Create a DataFrame with the average performance for each algorithm\n",
    "avg_performance_df = pd.DataFrame({'KNN': knn_avg_df, 'RF': rf_avg_df, 'LSTM': lstm_avg_df}, index=metric_columns)\n",
    "\n",
    "# Display the average performance for each algorithm\n",
    "print('\\n----- Average Performance for Each Algorithm -----\\n')\n",
    "print(avg_performance_df.round(decimals=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649629d8-046d-43f0-bf31-a9eed7c29a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
